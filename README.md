# ğŸ§  CyberSecurity Instruction-Finetuning  
**Fine-Tuning eines Sprachmodells mit H5P-Lerninhalten (Instruction-FT + PEFT/LoRA)**

![Python](https://img.shields.io/badge/Python-3.10+-blue)
![Transformers](https://img.shields.io/badge/HuggingFace-Transformers-yellow)
![PEFT](https://img.shields.io/badge/LoRA-Adapter-green)
![Status](https://img.shields.io/badge/Status-Research%20Prototype-orange)
![License](https://img.shields.io/badge/License-MIT-lightgrey)

---

## ğŸ§© ProjektÃ¼bersicht
Dieses Projekt untersucht, wie **H5P-Lerninhalte** (z. B. Quizfragen) genutzt werden kÃ¶nnen,  
um ein **Sprachmodell** mit **Instruction-Finetuning** und **Parameter-Efficient Fine-Tuning (PEFT/LoRA)** zu verbessern.  
Das Beispielthema ist *Cybersicherheit*.

Ziel: Ein Modell, das Lernfragen beantworten und erklÃ¤ren kann â€“ auf Basis realer H5P-Daten.

---

## ğŸ—‚ï¸ Projektstruktur

```bash
project/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Original H5P-Dateien
â”‚   â”œâ”€â”€ processed/          # Extrahierte JSONs
â”‚   â””â”€â”€ dataset.jsonl       # Finale Trainingsdaten fÃ¼r Instruction-FT
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extract_h5p.py      # Skript: H5P â†’ JSONL
â”‚   â”œâ”€â”€ train_instruction_ft.py  # Training mit HuggingFace + PEFT
â”‚   â””â”€â”€ utils/              # Hilfsfunktionen
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ data_preview.ipynb  # Dateninspektion
â”‚   â””â”€â”€ training_eval.ipynb # Evaluation des Trainings
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ training_config.yaml
â”‚   â””â”€â”€ model_config.json
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ checkpoints/        # Modellgewichte
â”‚   â”œâ”€â”€ logs/               # TensorBoard / W&B Logs
â”‚   â””â”€â”€ eval_results.json
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore
